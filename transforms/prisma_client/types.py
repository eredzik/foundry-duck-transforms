# -*- coding: utf-8 -*-
# code generated by Prisma. DO NOT EDIT.
# pyright: reportUnusedImport=false
# fmt: off

# global imports for type checking
from builtins import bool as _bool
from builtins import int as _int
from builtins import float as _float
from builtins import str as _str
import sys
import decimal
import datetime
from typing import (
    TYPE_CHECKING,
    Optional,
    Iterable,
    Iterator,
    Sequence,
    Callable,
    ClassVar,
    NoReturn,
    TypeVar,
    Generic,
    Mapping,
    Tuple,
    Union,
    List,
    Dict,
    Type,
    Any,
    Set,
    overload,
    cast,
)
from typing_extensions import TypedDict, Literal


from typing_extensions import LiteralString
# -- template types.py.jinja --
from typing import TypeVar

import httpx
from . import _types
from .utils import _NoneType



# TODO: filters with aggregates should have their own recursive fields
# TODO: cleanup whitespace control
# TODO: add an argument to signify that the last iteration should be skipped


SortMode = _types.SortMode
SortOrder = _types.SortOrder

MetricsFormat = _types.MetricsFormat

DatasourceOverride = _types.DatasourceOverride
HttpConfig = _types.HttpConfig


# types that can be serialized to json by our query builder
Serializable = Union[
    None,
    bool,
    float,
    int,
    str,
    datetime.datetime,
    List['Serializable'],
    Dict[None, 'Serializable'],
    Dict[bool, 'Serializable'],
    Dict[float, 'Serializable'],
    Dict[int, 'Serializable'],
    Dict[str, 'Serializable'],
]


StringFilter = TypedDict(
    'StringFilter',
    {
        'equals': str,
        'not_in': List[str],
        'lt': str,
        'lte': str,
        'gt': str,
        'gte': str,
        'contains': str,
        'startswith': str,
        'endswith': str,
        'in': List[str],
        'not': Union[str, 'StringFilter'],
                    },
    total=False,
)



class StringWithAggregatesFilter(StringFilter, total=False):
    _max: 'StringFilter'
    _min: 'StringFilter'
    _sum: 'StringFilter'
    _avg: 'StringFilter'
    _count: 'IntFilter'


DateTimeFilter = TypedDict(
    'DateTimeFilter',
    {
        'equals': datetime.datetime,
        'not_in': List[datetime.datetime],
        'lt': datetime.datetime,
        'lte': datetime.datetime,
        'gt': datetime.datetime,
        'gte': datetime.datetime,
        'in': List[datetime.datetime],
        'not': Union[datetime.datetime, 'DateTimeFilter'],
    },
    total=False,
)



class DateTimeWithAggregatesFilter(DateTimeFilter, total=False):
    _max: 'DateTimeFilter'
    _min: 'DateTimeFilter'
    _sum: 'DateTimeFilter'
    _avg: 'DateTimeFilter'
    _count: 'IntFilter'


BooleanFilter = TypedDict(
    'BooleanFilter',
    {
        'equals': bool,
        'not': Union[bool, 'BooleanFilter'],
    },
    total=False,
)



class BooleanWithAggregatesFilter(BooleanFilter, total=False):
    _max: 'BooleanFilter'
    _min: 'BooleanFilter'
    _sum: 'BooleanFilter'
    _avg: 'BooleanFilter'
    _count: 'IntFilter'


IntFilter = TypedDict(
    'IntFilter',
    {
        'equals': int,
        'not_in': List[int],
        'lt': int,
        'lte': int,
        'gt': int,
        'gte': int,
        'in': List[int],
        'not': Union[int, 'IntFilter'],
    },
    total=False,
)



class IntWithAggregatesFilter(IntFilter, total=False):
    _max: 'IntFilter'
    _min: 'IntFilter'
    _sum: 'IntFilter'
    _avg: 'IntFilter'
    _count: 'IntFilter'


BigIntFilter = IntFilter
BigIntWithAggregatesFilter = IntWithAggregatesFilter
FloatFilter = TypedDict(
    'FloatFilter',
    {
        'equals': float,
        'not_in': List[float],
        'lt': float,
        'lte': float,
        'gt': float,
        'gte': float,
        'in': List[float],
        'not': Union[float, 'FloatFilter'],
    },
    total=False,
)



class FloatWithAggregatesFilter(FloatFilter, total=False):
    _max: 'FloatFilter'
    _min: 'FloatFilter'
    _sum: 'FloatFilter'
    _avg: 'FloatFilter'
    _count: 'IntFilter'


BytesFilter = TypedDict(
    'BytesFilter',
    {
        'equals': 'fields.Base64',
        'in': List['fields.Base64'],
        'not_in': List['fields.Base64'],
        'not': Union['fields.Base64', 'BytesFilter'],
    },
    total=False,
)



class BytesWithAggregatesFilter(BytesFilter, total=False):
    _max: 'BytesFilter'
    _min: 'BytesFilter'
    _sum: 'BytesFilter'
    _avg: 'BytesFilter'
    _count: 'IntFilter'


# TODO: preview feature for improving JSON filtering
JsonFilter = TypedDict(
    'JsonFilter',
    {
        'equals': 'fields.Json',
        'not': 'fields.Json',
    },
    total=False,
)


class JsonWithAggregatesFilter(JsonFilter, total=False):
    _max: 'JsonFilter'
    _min: 'JsonFilter'
    _sum: 'JsonFilter'
    _avg: 'JsonFilter'
    _count: 'IntFilter'


DecimalFilter = TypedDict(
    'DecimalFilter',
    {
        'equals': decimal.Decimal,
        'not_in': List[decimal.Decimal],
        'lt': decimal.Decimal,
        'lte': decimal.Decimal,
        'gt': decimal.Decimal,
        'gte': decimal.Decimal,
        'in': List[decimal.Decimal],
        'not': Union[decimal.Decimal, 'DecimalFilter'],
    },
    total=False,
)



class DecimalWithAggregatesFilter(StringFilter, total=False):
    _max: 'DecimalFilter'
    _min: 'DecimalFilter'
    _sum: 'DecimalFilter'
    _avg: 'DecimalFilter'
    _count: 'IntFilter'


class _FloatSetInput(TypedDict):
    set: float


class _FloatDivideInput(TypedDict):
    divide: float


class _FloatMultiplyInput(TypedDict):
    multiply: float


class _FloatIncrementInput(TypedDict):
    increment: float


class _FloatDecrementInput(TypedDict):
    decrement: float


class _IntSetInput(TypedDict):
    set: int


class _IntDivideInput(TypedDict):
    divide: int


class _IntMultiplyInput(TypedDict):
    multiply: int


class _IntIncrementInput(TypedDict):
    increment: int


class _IntDecrementInput(TypedDict):
    decrement: int


AtomicFloatInput = Union[
    _FloatSetInput,
    _FloatDivideInput,
    _FloatMultiplyInput,
    _FloatIncrementInput,
    _FloatDecrementInput,
]
AtomicIntInput = Union[
    _IntSetInput,
    _IntDivideInput,
    _IntMultiplyInput,
    _IntIncrementInput,
    _IntDecrementInput,
]
AtomicBigIntInput = AtomicIntInput

class _StringListFilterEqualsInput(TypedDict):
    equals: Optional[List[_str]]


class _StringListFilterHasInput(TypedDict):
    has: _str


class _StringListFilterHasEveryInput(TypedDict):
    has_every: List[_str]


class _StringListFilterHasSomeInput(TypedDict):
    has_some: List[_str]


class _StringListFilterIsEmptyInput(TypedDict):
    is_empty: bool


StringListFilter = Union[
    _StringListFilterHasInput,
    _StringListFilterEqualsInput,
    _StringListFilterHasSomeInput,
    _StringListFilterIsEmptyInput,
    _StringListFilterHasEveryInput,
]


class _StringListUpdateSet(TypedDict):
    set: List[_str]


class _StringListUpdatePush(TypedDict):
    push: List[_str]


StringListUpdate = Union[
    List[_str],
    _StringListUpdateSet,
    _StringListUpdatePush,
]

class _BytesListFilterEqualsInput(TypedDict):
    equals: Optional[List['fields.Base64']]


class _BytesListFilterHasInput(TypedDict):
    has: 'fields.Base64'


class _BytesListFilterHasEveryInput(TypedDict):
    has_every: List['fields.Base64']


class _BytesListFilterHasSomeInput(TypedDict):
    has_some: List['fields.Base64']


class _BytesListFilterIsEmptyInput(TypedDict):
    is_empty: bool


BytesListFilter = Union[
    _BytesListFilterHasInput,
    _BytesListFilterEqualsInput,
    _BytesListFilterHasSomeInput,
    _BytesListFilterIsEmptyInput,
    _BytesListFilterHasEveryInput,
]


class _BytesListUpdateSet(TypedDict):
    set: List['fields.Base64']


class _BytesListUpdatePush(TypedDict):
    push: List['fields.Base64']


BytesListUpdate = Union[
    List['fields.Base64'],
    _BytesListUpdateSet,
    _BytesListUpdatePush,
]

class _DateTimeListFilterEqualsInput(TypedDict):
    equals: Optional[List[datetime.datetime]]


class _DateTimeListFilterHasInput(TypedDict):
    has: datetime.datetime


class _DateTimeListFilterHasEveryInput(TypedDict):
    has_every: List[datetime.datetime]


class _DateTimeListFilterHasSomeInput(TypedDict):
    has_some: List[datetime.datetime]


class _DateTimeListFilterIsEmptyInput(TypedDict):
    is_empty: bool


DateTimeListFilter = Union[
    _DateTimeListFilterHasInput,
    _DateTimeListFilterEqualsInput,
    _DateTimeListFilterHasSomeInput,
    _DateTimeListFilterIsEmptyInput,
    _DateTimeListFilterHasEveryInput,
]


class _DateTimeListUpdateSet(TypedDict):
    set: List[datetime.datetime]


class _DateTimeListUpdatePush(TypedDict):
    push: List[datetime.datetime]


DateTimeListUpdate = Union[
    List[datetime.datetime],
    _DateTimeListUpdateSet,
    _DateTimeListUpdatePush,
]

class _BooleanListFilterEqualsInput(TypedDict):
    equals: Optional[List[_bool]]


class _BooleanListFilterHasInput(TypedDict):
    has: _bool


class _BooleanListFilterHasEveryInput(TypedDict):
    has_every: List[_bool]


class _BooleanListFilterHasSomeInput(TypedDict):
    has_some: List[_bool]


class _BooleanListFilterIsEmptyInput(TypedDict):
    is_empty: bool


BooleanListFilter = Union[
    _BooleanListFilterHasInput,
    _BooleanListFilterEqualsInput,
    _BooleanListFilterHasSomeInput,
    _BooleanListFilterIsEmptyInput,
    _BooleanListFilterHasEveryInput,
]


class _BooleanListUpdateSet(TypedDict):
    set: List[_bool]


class _BooleanListUpdatePush(TypedDict):
    push: List[_bool]


BooleanListUpdate = Union[
    List[_bool],
    _BooleanListUpdateSet,
    _BooleanListUpdatePush,
]

class _IntListFilterEqualsInput(TypedDict):
    equals: Optional[List[_int]]


class _IntListFilterHasInput(TypedDict):
    has: _int


class _IntListFilterHasEveryInput(TypedDict):
    has_every: List[_int]


class _IntListFilterHasSomeInput(TypedDict):
    has_some: List[_int]


class _IntListFilterIsEmptyInput(TypedDict):
    is_empty: bool


IntListFilter = Union[
    _IntListFilterHasInput,
    _IntListFilterEqualsInput,
    _IntListFilterHasSomeInput,
    _IntListFilterIsEmptyInput,
    _IntListFilterHasEveryInput,
]


class _IntListUpdateSet(TypedDict):
    set: List[_int]


class _IntListUpdatePush(TypedDict):
    push: List[_int]


IntListUpdate = Union[
    List[_int],
    _IntListUpdateSet,
    _IntListUpdatePush,
]

class _BigIntListFilterEqualsInput(TypedDict):
    equals: Optional[List[_int]]


class _BigIntListFilterHasInput(TypedDict):
    has: _int


class _BigIntListFilterHasEveryInput(TypedDict):
    has_every: List[_int]


class _BigIntListFilterHasSomeInput(TypedDict):
    has_some: List[_int]


class _BigIntListFilterIsEmptyInput(TypedDict):
    is_empty: bool


BigIntListFilter = Union[
    _BigIntListFilterHasInput,
    _BigIntListFilterEqualsInput,
    _BigIntListFilterHasSomeInput,
    _BigIntListFilterIsEmptyInput,
    _BigIntListFilterHasEveryInput,
]


class _BigIntListUpdateSet(TypedDict):
    set: List[_int]


class _BigIntListUpdatePush(TypedDict):
    push: List[_int]


BigIntListUpdate = Union[
    List[_int],
    _BigIntListUpdateSet,
    _BigIntListUpdatePush,
]

class _FloatListFilterEqualsInput(TypedDict):
    equals: Optional[List[_float]]


class _FloatListFilterHasInput(TypedDict):
    has: _float


class _FloatListFilterHasEveryInput(TypedDict):
    has_every: List[_float]


class _FloatListFilterHasSomeInput(TypedDict):
    has_some: List[_float]


class _FloatListFilterIsEmptyInput(TypedDict):
    is_empty: bool


FloatListFilter = Union[
    _FloatListFilterHasInput,
    _FloatListFilterEqualsInput,
    _FloatListFilterHasSomeInput,
    _FloatListFilterIsEmptyInput,
    _FloatListFilterHasEveryInput,
]


class _FloatListUpdateSet(TypedDict):
    set: List[_float]


class _FloatListUpdatePush(TypedDict):
    push: List[_float]


FloatListUpdate = Union[
    List[_float],
    _FloatListUpdateSet,
    _FloatListUpdatePush,
]

class _JsonListFilterEqualsInput(TypedDict):
    equals: Optional[List['fields.Json']]


class _JsonListFilterHasInput(TypedDict):
    has: 'fields.Json'


class _JsonListFilterHasEveryInput(TypedDict):
    has_every: List['fields.Json']


class _JsonListFilterHasSomeInput(TypedDict):
    has_some: List['fields.Json']


class _JsonListFilterIsEmptyInput(TypedDict):
    is_empty: bool


JsonListFilter = Union[
    _JsonListFilterHasInput,
    _JsonListFilterEqualsInput,
    _JsonListFilterHasSomeInput,
    _JsonListFilterIsEmptyInput,
    _JsonListFilterHasEveryInput,
]


class _JsonListUpdateSet(TypedDict):
    set: List['fields.Json']


class _JsonListUpdatePush(TypedDict):
    push: List['fields.Json']


JsonListUpdate = Union[
    List['fields.Json'],
    _JsonListUpdateSet,
    _JsonListUpdatePush,
]

class _DecimalListFilterEqualsInput(TypedDict):
    equals: Optional[List[decimal.Decimal]]


class _DecimalListFilterHasInput(TypedDict):
    has: decimal.Decimal


class _DecimalListFilterHasEveryInput(TypedDict):
    has_every: List[decimal.Decimal]


class _DecimalListFilterHasSomeInput(TypedDict):
    has_some: List[decimal.Decimal]


class _DecimalListFilterIsEmptyInput(TypedDict):
    is_empty: bool


DecimalListFilter = Union[
    _DecimalListFilterHasInput,
    _DecimalListFilterEqualsInput,
    _DecimalListFilterHasSomeInput,
    _DecimalListFilterIsEmptyInput,
    _DecimalListFilterHasEveryInput,
]


class _DecimalListUpdateSet(TypedDict):
    set: List[decimal.Decimal]


class _DecimalListUpdatePush(TypedDict):
    push: List[decimal.Decimal]


DecimalListUpdate = Union[
    List[decimal.Decimal],
    _DecimalListUpdateSet,
    _DecimalListUpdatePush,
]


# dataset types

class datasetOptionalCreateInput(TypedDict, total=False):
    """Optional arguments to the dataset create method"""
    id: _int
    dataset_identifier: 'dataset_identifierCreateManyNestedWithoutRelationsInput'
    dataset_version: 'dataset_versionCreateManyNestedWithoutRelationsInput'


class datasetCreateInput(datasetOptionalCreateInput):
    """Required arguments to the dataset create method"""
    rid: _str


# TODO: remove this in favour of without explicit relations
# e.g. PostCreateWithoutAuthorInput

class datasetOptionalCreateWithoutRelationsInput(TypedDict, total=False):
    """Optional arguments to the dataset create method, without relations"""
    id: _int


class datasetCreateWithoutRelationsInput(datasetOptionalCreateWithoutRelationsInput):
    """Required arguments to the dataset create method, without relations"""
    rid: _str

class datasetConnectOrCreateWithoutRelationsInput(TypedDict):
    create: 'datasetCreateWithoutRelationsInput'
    where: 'datasetWhereUniqueInput'

class datasetCreateNestedWithoutRelationsInput(TypedDict, total=False):
    create: 'datasetCreateWithoutRelationsInput'
    connect: 'datasetWhereUniqueInput'
    connect_or_create: 'datasetConnectOrCreateWithoutRelationsInput'


class datasetCreateManyNestedWithoutRelationsInput(TypedDict, total=False):
    create: Union['datasetCreateWithoutRelationsInput', List['datasetCreateWithoutRelationsInput']]
    connect: Union['datasetWhereUniqueInput', List['datasetWhereUniqueInput']]
    connect_or_create: Union['datasetConnectOrCreateWithoutRelationsInput', List['datasetConnectOrCreateWithoutRelationsInput']]

_datasetWhereUnique_id_Input = TypedDict(
    '_datasetWhereUnique_id_Input',
    {
        'id': '_int',
    },
    total=True
)

datasetWhereUniqueInput = _datasetWhereUnique_id_Input


class datasetUpdateInput(TypedDict, total=False):
    """Optional arguments for updating a record"""
    id: Union[AtomicIntInput, _int]
    rid: _str
    dataset_identifier: 'dataset_identifierUpdateManyWithoutRelationsInput'
    dataset_version: 'dataset_versionUpdateManyWithoutRelationsInput'


class datasetUpdateManyMutationInput(TypedDict, total=False):
    """Arguments for updating many records"""
    id: Union[AtomicIntInput, _int]
    rid: _str


class datasetUpdateManyWithoutRelationsInput(TypedDict, total=False):
    create: List['datasetCreateWithoutRelationsInput']
    connect: List['datasetWhereUniqueInput']
    connect_or_create: List['datasetConnectOrCreateWithoutRelationsInput']
    set: List['datasetWhereUniqueInput']
    disconnect: List['datasetWhereUniqueInput']
    delete: List['datasetWhereUniqueInput']

    # TODO
    # update: List['datasetUpdateWithWhereUniqueWithoutRelationsInput']
    # updateMany: List['datasetUpdateManyWithWhereUniqueWithoutRelationsInput']
    # deleteMany: List['datasetScalarWhereInput']
    # upsert: List['datasetUpserteWithWhereUniqueWithoutRelationsInput']


class datasetUpdateOneWithoutRelationsInput(TypedDict, total=False):
    create: 'datasetCreateWithoutRelationsInput'
    connect: 'datasetWhereUniqueInput'
    connect_or_create: 'datasetConnectOrCreateWithoutRelationsInput'
    disconnect: bool
    delete: bool

    # TODO
    # update: 'datasetUpdateInput'
    # upsert: 'datasetUpsertWithoutRelationsInput'


class datasetUpsertInput(TypedDict):
    create: 'datasetCreateInput'
    update: 'datasetUpdateInput'  # pyright: ignore[reportIncompatibleMethodOverride]


_dataset_id_OrderByInput = TypedDict(
    '_dataset_id_OrderByInput',
    {
        'id': 'SortOrder',
    },
    total=True
)

_dataset_rid_OrderByInput = TypedDict(
    '_dataset_rid_OrderByInput',
    {
        'rid': 'SortOrder',
    },
    total=True
)

datasetOrderByInput = Union[
    '_dataset_id_OrderByInput',
    '_dataset_rid_OrderByInput',
]



# recursive dataset types
# TODO: cleanup these types



datasetRelationFilter = TypedDict(
    'datasetRelationFilter',
    {
        'is': 'datasetWhereInput',
        'is_not': 'datasetWhereInput',
    },
    total=False,
)


class datasetListRelationFilter(TypedDict, total=False):
    some: 'datasetWhereInput'
    none: 'datasetWhereInput'
    every: 'datasetWhereInput'


class datasetInclude(TypedDict, total=False):
    """dataset relational arguments"""
    dataset_identifier: Union[bool, 'FindManydataset_identifierArgsFromdataset']
    dataset_version: Union[bool, 'FindManydataset_versionArgsFromdataset']


class datasetIncludeFromdataset(TypedDict, total=False):
    """Relational arguments for dataset"""
    dataset_identifier: Union[bool, 'FindManydataset_identifierArgsFromdataset']
    dataset_version: Union[bool, 'FindManydataset_versionArgsFromdataset']


class datasetArgsFromdataset(TypedDict, total=False):
    """Arguments for dataset"""
    include: 'datasetIncludeFromdataset'


class FindManydatasetArgsFromdataset(TypedDict, total=False):
    """Arguments for dataset"""
    take: int
    skip: int
    order_by: Union['datasetOrderByInput', List['datasetOrderByInput']]
    where: 'datasetWhereInput'
    cursor: 'datasetWhereUniqueInput'
    distinct: List['datasetScalarFieldKeys']
    include: 'datasetIncludeFromdataset'


class dataset_identifierIncludeFromdataset(TypedDict, total=False):
    """Relational arguments for dataset"""
    dataset: Union[bool, 'datasetArgsFromdataset']


class dataset_identifierArgsFromdataset(TypedDict, total=False):
    """Arguments for dataset"""
    include: 'dataset_identifierIncludeFromdataset_identifier'


class FindManydataset_identifierArgsFromdataset(TypedDict, total=False):
    """Arguments for dataset"""
    take: int
    skip: int
    order_by: Union['dataset_identifierOrderByInput', List['dataset_identifierOrderByInput']]
    where: 'dataset_identifierWhereInput'
    cursor: 'dataset_identifierWhereUniqueInput'
    distinct: List['dataset_identifierScalarFieldKeys']
    include: 'dataset_identifierIncludeFromdataset_identifier'


class dataset_versionIncludeFromdataset(TypedDict, total=False):
    """Relational arguments for dataset"""
    branch: Union[bool, 'data_branchArgsFromdataset']
    dataset: Union[bool, 'datasetArgsFromdataset']


class dataset_versionArgsFromdataset(TypedDict, total=False):
    """Arguments for dataset"""
    include: 'dataset_versionIncludeFromdataset_version'


class FindManydataset_versionArgsFromdataset(TypedDict, total=False):
    """Arguments for dataset"""
    take: int
    skip: int
    order_by: Union['dataset_versionOrderByInput', List['dataset_versionOrderByInput']]
    where: 'dataset_versionWhereInput'
    cursor: 'dataset_versionWhereUniqueInput'
    distinct: List['dataset_versionScalarFieldKeys']
    include: 'dataset_versionIncludeFromdataset_version'


class data_branchIncludeFromdataset(TypedDict, total=False):
    """Relational arguments for dataset"""
    dataset_version: Union[bool, 'FindManydataset_versionArgsFromdataset']


class data_branchArgsFromdataset(TypedDict, total=False):
    """Arguments for dataset"""
    include: 'data_branchIncludeFromdata_branch'


class FindManydata_branchArgsFromdataset(TypedDict, total=False):
    """Arguments for dataset"""
    take: int
    skip: int
    order_by: Union['data_branchOrderByInput', List['data_branchOrderByInput']]
    where: 'data_branchWhereInput'
    cursor: 'data_branchWhereUniqueInput'
    distinct: List['data_branchScalarFieldKeys']
    include: 'data_branchIncludeFromdata_branch'




FindManydatasetArgs = FindManydatasetArgsFromdataset
FindFirstdatasetArgs = FindManydatasetArgsFromdataset


class datasetWhereInput(TypedDict, total=False):
    """dataset arguments for searching"""
    id: Union[_int, 'types.IntFilter']
    rid: Union[_str, 'types.StringFilter']
    dataset_identifier: 'dataset_identifierListRelationFilter'
    dataset_version: 'dataset_versionListRelationFilter'

    # should be noted that AND and NOT should be Union['datasetWhereInput', List['datasetWhereInput']]
    # but this causes mypy to hang :/
    AND: List['datasetWhereInput']
    OR: List['datasetWhereInput']
    NOT: List['datasetWhereInput']



# aggregate dataset types


class datasetScalarWhereWithAggregatesInput(TypedDict, total=False):
    """dataset arguments for searching"""
    id: Union[_int, 'types.IntWithAggregatesFilter']
    rid: Union[_str, 'types.StringWithAggregatesFilter']

    AND: List['datasetScalarWhereWithAggregatesInput']
    OR: List['datasetScalarWhereWithAggregatesInput']
    NOT: List['datasetScalarWhereWithAggregatesInput']



class datasetGroupByOutput(TypedDict, total=False):
    id: _int
    rid: _str
    _sum: 'datasetSumAggregateOutput'
    _avg: 'datasetAvgAggregateOutput'
    _min: 'datasetMinAggregateOutput'
    _max: 'datasetMaxAggregateOutput'
    _count: 'datasetCountAggregateOutput'


class datasetAvgAggregateOutput(TypedDict, total=False):
    """dataset output for aggregating averages"""
    id: float


class datasetSumAggregateOutput(TypedDict, total=False):
    """dataset output for aggregating sums"""
    id: _int


class datasetScalarAggregateOutput(TypedDict, total=False):
    """dataset output including scalar fields"""
    id: _int
    rid: _str


datasetMinAggregateOutput = datasetScalarAggregateOutput
datasetMaxAggregateOutput = datasetScalarAggregateOutput


class datasetMaxAggregateInput(TypedDict, total=False):
    """dataset input for aggregating by max"""
    id: bool
    rid: bool


class datasetMinAggregateInput(TypedDict, total=False):
    """dataset input for aggregating by min"""
    id: bool
    rid: bool


class datasetNumberAggregateInput(TypedDict, total=False):
    """dataset input for aggregating numbers"""
    id: bool


datasetAvgAggregateInput = datasetNumberAggregateInput
datasetSumAggregateInput = datasetNumberAggregateInput


datasetCountAggregateInput = TypedDict(
    'datasetCountAggregateInput',
    {
        'id': bool,
        'rid': bool,
        '_all': bool,
    },
    total=False,
)

datasetCountAggregateOutput = TypedDict(
    'datasetCountAggregateOutput',
    {
        'id': int,
        'rid': int,
        '_all': int,
    },
    total=False,
)


datasetKeys = Literal[
    'id',
    'rid',
    'dataset_identifier',
    'dataset_version',
]
datasetScalarFieldKeys = Literal[
    'id',
    'rid',
]
datasetScalarFieldKeysT = TypeVar('datasetScalarFieldKeysT', bound=datasetScalarFieldKeys)

datasetRelationalFieldKeys = Literal[
        'dataset_identifier',
        'dataset_version',
    ]

# dataset_identifier types

class dataset_identifierOptionalCreateInput(TypedDict, total=False):
    """Optional arguments to the dataset_identifier create method"""
    id: _int
    dataset: 'datasetCreateNestedWithoutRelationsInput'
    datasetid: _int


class dataset_identifierCreateInput(dataset_identifierOptionalCreateInput):
    """Required arguments to the dataset_identifier create method"""
    rid_or_path: _str


# TODO: remove this in favour of without explicit relations
# e.g. PostCreateWithoutAuthorInput

class dataset_identifierOptionalCreateWithoutRelationsInput(TypedDict, total=False):
    """Optional arguments to the dataset_identifier create method, without relations"""
    id: _int
    datasetid: _int


class dataset_identifierCreateWithoutRelationsInput(dataset_identifierOptionalCreateWithoutRelationsInput):
    """Required arguments to the dataset_identifier create method, without relations"""
    rid_or_path: _str

class dataset_identifierConnectOrCreateWithoutRelationsInput(TypedDict):
    create: 'dataset_identifierCreateWithoutRelationsInput'
    where: 'dataset_identifierWhereUniqueInput'

class dataset_identifierCreateNestedWithoutRelationsInput(TypedDict, total=False):
    create: 'dataset_identifierCreateWithoutRelationsInput'
    connect: 'dataset_identifierWhereUniqueInput'
    connect_or_create: 'dataset_identifierConnectOrCreateWithoutRelationsInput'


class dataset_identifierCreateManyNestedWithoutRelationsInput(TypedDict, total=False):
    create: Union['dataset_identifierCreateWithoutRelationsInput', List['dataset_identifierCreateWithoutRelationsInput']]
    connect: Union['dataset_identifierWhereUniqueInput', List['dataset_identifierWhereUniqueInput']]
    connect_or_create: Union['dataset_identifierConnectOrCreateWithoutRelationsInput', List['dataset_identifierConnectOrCreateWithoutRelationsInput']]

_dataset_identifierWhereUnique_id_Input = TypedDict(
    '_dataset_identifierWhereUnique_id_Input',
    {
        'id': '_int',
    },
    total=True
)

dataset_identifierWhereUniqueInput = _dataset_identifierWhereUnique_id_Input


class dataset_identifierUpdateInput(TypedDict, total=False):
    """Optional arguments for updating a record"""
    id: Union[AtomicIntInput, _int]
    rid_or_path: _str
    dataset: 'datasetUpdateOneWithoutRelationsInput'


class dataset_identifierUpdateManyMutationInput(TypedDict, total=False):
    """Arguments for updating many records"""
    id: Union[AtomicIntInput, _int]
    rid_or_path: _str


class dataset_identifierUpdateManyWithoutRelationsInput(TypedDict, total=False):
    create: List['dataset_identifierCreateWithoutRelationsInput']
    connect: List['dataset_identifierWhereUniqueInput']
    connect_or_create: List['dataset_identifierConnectOrCreateWithoutRelationsInput']
    set: List['dataset_identifierWhereUniqueInput']
    disconnect: List['dataset_identifierWhereUniqueInput']
    delete: List['dataset_identifierWhereUniqueInput']

    # TODO
    # update: List['dataset_identifierUpdateWithWhereUniqueWithoutRelationsInput']
    # updateMany: List['dataset_identifierUpdateManyWithWhereUniqueWithoutRelationsInput']
    # deleteMany: List['dataset_identifierScalarWhereInput']
    # upsert: List['dataset_identifierUpserteWithWhereUniqueWithoutRelationsInput']


class dataset_identifierUpdateOneWithoutRelationsInput(TypedDict, total=False):
    create: 'dataset_identifierCreateWithoutRelationsInput'
    connect: 'dataset_identifierWhereUniqueInput'
    connect_or_create: 'dataset_identifierConnectOrCreateWithoutRelationsInput'
    disconnect: bool
    delete: bool

    # TODO
    # update: 'dataset_identifierUpdateInput'
    # upsert: 'dataset_identifierUpsertWithoutRelationsInput'


class dataset_identifierUpsertInput(TypedDict):
    create: 'dataset_identifierCreateInput'
    update: 'dataset_identifierUpdateInput'  # pyright: ignore[reportIncompatibleMethodOverride]


_dataset_identifier_id_OrderByInput = TypedDict(
    '_dataset_identifier_id_OrderByInput',
    {
        'id': 'SortOrder',
    },
    total=True
)

_dataset_identifier_rid_or_path_OrderByInput = TypedDict(
    '_dataset_identifier_rid_or_path_OrderByInput',
    {
        'rid_or_path': 'SortOrder',
    },
    total=True
)

_dataset_identifier_datasetid_OrderByInput = TypedDict(
    '_dataset_identifier_datasetid_OrderByInput',
    {
        'datasetid': 'SortOrder',
    },
    total=True
)

dataset_identifierOrderByInput = Union[
    '_dataset_identifier_id_OrderByInput',
    '_dataset_identifier_rid_or_path_OrderByInput',
    '_dataset_identifier_datasetid_OrderByInput',
]



# recursive dataset_identifier types
# TODO: cleanup these types



dataset_identifierRelationFilter = TypedDict(
    'dataset_identifierRelationFilter',
    {
        'is': 'dataset_identifierWhereInput',
        'is_not': 'dataset_identifierWhereInput',
    },
    total=False,
)


class dataset_identifierListRelationFilter(TypedDict, total=False):
    some: 'dataset_identifierWhereInput'
    none: 'dataset_identifierWhereInput'
    every: 'dataset_identifierWhereInput'


class dataset_identifierInclude(TypedDict, total=False):
    """dataset_identifier relational arguments"""
    dataset: Union[bool, 'datasetArgsFromdataset_identifier']


class datasetIncludeFromdataset_identifier(TypedDict, total=False):
    """Relational arguments for dataset_identifier"""
    dataset_identifier: Union[bool, 'FindManydataset_identifierArgsFromdataset_identifier']
    dataset_version: Union[bool, 'FindManydataset_versionArgsFromdataset_identifier']


class datasetArgsFromdataset_identifier(TypedDict, total=False):
    """Arguments for dataset_identifier"""
    include: 'datasetIncludeFromdataset'


class FindManydatasetArgsFromdataset_identifier(TypedDict, total=False):
    """Arguments for dataset_identifier"""
    take: int
    skip: int
    order_by: Union['datasetOrderByInput', List['datasetOrderByInput']]
    where: 'datasetWhereInput'
    cursor: 'datasetWhereUniqueInput'
    distinct: List['datasetScalarFieldKeys']
    include: 'datasetIncludeFromdataset'


class dataset_identifierIncludeFromdataset_identifier(TypedDict, total=False):
    """Relational arguments for dataset_identifier"""
    dataset: Union[bool, 'datasetArgsFromdataset_identifier']


class dataset_identifierArgsFromdataset_identifier(TypedDict, total=False):
    """Arguments for dataset_identifier"""
    include: 'dataset_identifierIncludeFromdataset_identifier'


class FindManydataset_identifierArgsFromdataset_identifier(TypedDict, total=False):
    """Arguments for dataset_identifier"""
    take: int
    skip: int
    order_by: Union['dataset_identifierOrderByInput', List['dataset_identifierOrderByInput']]
    where: 'dataset_identifierWhereInput'
    cursor: 'dataset_identifierWhereUniqueInput'
    distinct: List['dataset_identifierScalarFieldKeys']
    include: 'dataset_identifierIncludeFromdataset_identifier'


class dataset_versionIncludeFromdataset_identifier(TypedDict, total=False):
    """Relational arguments for dataset_identifier"""
    branch: Union[bool, 'data_branchArgsFromdataset_identifier']
    dataset: Union[bool, 'datasetArgsFromdataset_identifier']


class dataset_versionArgsFromdataset_identifier(TypedDict, total=False):
    """Arguments for dataset_identifier"""
    include: 'dataset_versionIncludeFromdataset_version'


class FindManydataset_versionArgsFromdataset_identifier(TypedDict, total=False):
    """Arguments for dataset_identifier"""
    take: int
    skip: int
    order_by: Union['dataset_versionOrderByInput', List['dataset_versionOrderByInput']]
    where: 'dataset_versionWhereInput'
    cursor: 'dataset_versionWhereUniqueInput'
    distinct: List['dataset_versionScalarFieldKeys']
    include: 'dataset_versionIncludeFromdataset_version'


class data_branchIncludeFromdataset_identifier(TypedDict, total=False):
    """Relational arguments for dataset_identifier"""
    dataset_version: Union[bool, 'FindManydataset_versionArgsFromdataset_identifier']


class data_branchArgsFromdataset_identifier(TypedDict, total=False):
    """Arguments for dataset_identifier"""
    include: 'data_branchIncludeFromdata_branch'


class FindManydata_branchArgsFromdataset_identifier(TypedDict, total=False):
    """Arguments for dataset_identifier"""
    take: int
    skip: int
    order_by: Union['data_branchOrderByInput', List['data_branchOrderByInput']]
    where: 'data_branchWhereInput'
    cursor: 'data_branchWhereUniqueInput'
    distinct: List['data_branchScalarFieldKeys']
    include: 'data_branchIncludeFromdata_branch'




FindManydataset_identifierArgs = FindManydataset_identifierArgsFromdataset_identifier
FindFirstdataset_identifierArgs = FindManydataset_identifierArgsFromdataset_identifier


class dataset_identifierWhereInput(TypedDict, total=False):
    """dataset_identifier arguments for searching"""
    id: Union[_int, 'types.IntFilter']
    rid_or_path: Union[_str, 'types.StringFilter']
    dataset: 'datasetRelationFilter'
    datasetid: Union[_int, 'types.IntFilter']

    # should be noted that AND and NOT should be Union['dataset_identifierWhereInput', List['dataset_identifierWhereInput']]
    # but this causes mypy to hang :/
    AND: List['dataset_identifierWhereInput']
    OR: List['dataset_identifierWhereInput']
    NOT: List['dataset_identifierWhereInput']



# aggregate dataset_identifier types


class dataset_identifierScalarWhereWithAggregatesInput(TypedDict, total=False):
    """dataset_identifier arguments for searching"""
    id: Union[_int, 'types.IntWithAggregatesFilter']
    rid_or_path: Union[_str, 'types.StringWithAggregatesFilter']
    datasetid: Union[_int, 'types.IntWithAggregatesFilter']

    AND: List['dataset_identifierScalarWhereWithAggregatesInput']
    OR: List['dataset_identifierScalarWhereWithAggregatesInput']
    NOT: List['dataset_identifierScalarWhereWithAggregatesInput']



class dataset_identifierGroupByOutput(TypedDict, total=False):
    id: _int
    rid_or_path: _str
    datasetid: _int
    _sum: 'dataset_identifierSumAggregateOutput'
    _avg: 'dataset_identifierAvgAggregateOutput'
    _min: 'dataset_identifierMinAggregateOutput'
    _max: 'dataset_identifierMaxAggregateOutput'
    _count: 'dataset_identifierCountAggregateOutput'


class dataset_identifierAvgAggregateOutput(TypedDict, total=False):
    """dataset_identifier output for aggregating averages"""
    id: float
    datasetid: float


class dataset_identifierSumAggregateOutput(TypedDict, total=False):
    """dataset_identifier output for aggregating sums"""
    id: _int
    datasetid: _int


class dataset_identifierScalarAggregateOutput(TypedDict, total=False):
    """dataset_identifier output including scalar fields"""
    id: _int
    rid_or_path: _str
    datasetid: _int


dataset_identifierMinAggregateOutput = dataset_identifierScalarAggregateOutput
dataset_identifierMaxAggregateOutput = dataset_identifierScalarAggregateOutput


class dataset_identifierMaxAggregateInput(TypedDict, total=False):
    """dataset_identifier input for aggregating by max"""
    id: bool
    rid_or_path: bool
    datasetid: bool


class dataset_identifierMinAggregateInput(TypedDict, total=False):
    """dataset_identifier input for aggregating by min"""
    id: bool
    rid_or_path: bool
    datasetid: bool


class dataset_identifierNumberAggregateInput(TypedDict, total=False):
    """dataset_identifier input for aggregating numbers"""
    id: bool
    datasetid: bool


dataset_identifierAvgAggregateInput = dataset_identifierNumberAggregateInput
dataset_identifierSumAggregateInput = dataset_identifierNumberAggregateInput


dataset_identifierCountAggregateInput = TypedDict(
    'dataset_identifierCountAggregateInput',
    {
        'id': bool,
        'rid_or_path': bool,
        'datasetid': bool,
        '_all': bool,
    },
    total=False,
)

dataset_identifierCountAggregateOutput = TypedDict(
    'dataset_identifierCountAggregateOutput',
    {
        'id': int,
        'rid_or_path': int,
        'datasetid': int,
        '_all': int,
    },
    total=False,
)


dataset_identifierKeys = Literal[
    'id',
    'rid_or_path',
    'dataset',
    'datasetid',
]
dataset_identifierScalarFieldKeys = Literal[
    'id',
    'rid_or_path',
    'datasetid',
]
dataset_identifierScalarFieldKeysT = TypeVar('dataset_identifierScalarFieldKeysT', bound=dataset_identifierScalarFieldKeys)

dataset_identifierRelationalFieldKeys = Literal[
        'dataset',
    ]

# dataset_version types

class dataset_versionOptionalCreateInput(TypedDict, total=False):
    """Optional arguments to the dataset_version create method"""
    id: _int
    data_identity_date: datetime.datetime
    branch: 'data_branchCreateNestedWithoutRelationsInput'
    dataset: 'datasetCreateNestedWithoutRelationsInput'
    datasetId: _int
    data_branchId: _int


class dataset_versionCreateInput(dataset_versionOptionalCreateInput):
    """Required arguments to the dataset_version create method"""
    data_identity_id: _str


# TODO: remove this in favour of without explicit relations
# e.g. PostCreateWithoutAuthorInput

class dataset_versionOptionalCreateWithoutRelationsInput(TypedDict, total=False):
    """Optional arguments to the dataset_version create method, without relations"""
    id: _int
    data_identity_date: datetime.datetime
    datasetId: _int
    data_branchId: _int


class dataset_versionCreateWithoutRelationsInput(dataset_versionOptionalCreateWithoutRelationsInput):
    """Required arguments to the dataset_version create method, without relations"""
    data_identity_id: _str

class dataset_versionConnectOrCreateWithoutRelationsInput(TypedDict):
    create: 'dataset_versionCreateWithoutRelationsInput'
    where: 'dataset_versionWhereUniqueInput'

class dataset_versionCreateNestedWithoutRelationsInput(TypedDict, total=False):
    create: 'dataset_versionCreateWithoutRelationsInput'
    connect: 'dataset_versionWhereUniqueInput'
    connect_or_create: 'dataset_versionConnectOrCreateWithoutRelationsInput'


class dataset_versionCreateManyNestedWithoutRelationsInput(TypedDict, total=False):
    create: Union['dataset_versionCreateWithoutRelationsInput', List['dataset_versionCreateWithoutRelationsInput']]
    connect: Union['dataset_versionWhereUniqueInput', List['dataset_versionWhereUniqueInput']]
    connect_or_create: Union['dataset_versionConnectOrCreateWithoutRelationsInput', List['dataset_versionConnectOrCreateWithoutRelationsInput']]

_dataset_versionWhereUnique_id_Input = TypedDict(
    '_dataset_versionWhereUnique_id_Input',
    {
        'id': '_int',
    },
    total=True
)

dataset_versionWhereUniqueInput = _dataset_versionWhereUnique_id_Input


class dataset_versionUpdateInput(TypedDict, total=False):
    """Optional arguments for updating a record"""
    id: Union[AtomicIntInput, _int]
    data_identity_id: _str
    data_identity_date: datetime.datetime
    branch: 'data_branchUpdateOneWithoutRelationsInput'
    dataset: 'datasetUpdateOneWithoutRelationsInput'


class dataset_versionUpdateManyMutationInput(TypedDict, total=False):
    """Arguments for updating many records"""
    id: Union[AtomicIntInput, _int]
    data_identity_id: _str
    data_identity_date: datetime.datetime


class dataset_versionUpdateManyWithoutRelationsInput(TypedDict, total=False):
    create: List['dataset_versionCreateWithoutRelationsInput']
    connect: List['dataset_versionWhereUniqueInput']
    connect_or_create: List['dataset_versionConnectOrCreateWithoutRelationsInput']
    set: List['dataset_versionWhereUniqueInput']
    disconnect: List['dataset_versionWhereUniqueInput']
    delete: List['dataset_versionWhereUniqueInput']

    # TODO
    # update: List['dataset_versionUpdateWithWhereUniqueWithoutRelationsInput']
    # updateMany: List['dataset_versionUpdateManyWithWhereUniqueWithoutRelationsInput']
    # deleteMany: List['dataset_versionScalarWhereInput']
    # upsert: List['dataset_versionUpserteWithWhereUniqueWithoutRelationsInput']


class dataset_versionUpdateOneWithoutRelationsInput(TypedDict, total=False):
    create: 'dataset_versionCreateWithoutRelationsInput'
    connect: 'dataset_versionWhereUniqueInput'
    connect_or_create: 'dataset_versionConnectOrCreateWithoutRelationsInput'
    disconnect: bool
    delete: bool

    # TODO
    # update: 'dataset_versionUpdateInput'
    # upsert: 'dataset_versionUpsertWithoutRelationsInput'


class dataset_versionUpsertInput(TypedDict):
    create: 'dataset_versionCreateInput'
    update: 'dataset_versionUpdateInput'  # pyright: ignore[reportIncompatibleMethodOverride]


_dataset_version_id_OrderByInput = TypedDict(
    '_dataset_version_id_OrderByInput',
    {
        'id': 'SortOrder',
    },
    total=True
)

_dataset_version_data_identity_id_OrderByInput = TypedDict(
    '_dataset_version_data_identity_id_OrderByInput',
    {
        'data_identity_id': 'SortOrder',
    },
    total=True
)

_dataset_version_data_identity_date_OrderByInput = TypedDict(
    '_dataset_version_data_identity_date_OrderByInput',
    {
        'data_identity_date': 'SortOrder',
    },
    total=True
)

_dataset_version_datasetId_OrderByInput = TypedDict(
    '_dataset_version_datasetId_OrderByInput',
    {
        'datasetId': 'SortOrder',
    },
    total=True
)

_dataset_version_data_branchId_OrderByInput = TypedDict(
    '_dataset_version_data_branchId_OrderByInput',
    {
        'data_branchId': 'SortOrder',
    },
    total=True
)

dataset_versionOrderByInput = Union[
    '_dataset_version_id_OrderByInput',
    '_dataset_version_data_identity_id_OrderByInput',
    '_dataset_version_data_identity_date_OrderByInput',
    '_dataset_version_datasetId_OrderByInput',
    '_dataset_version_data_branchId_OrderByInput',
]



# recursive dataset_version types
# TODO: cleanup these types



dataset_versionRelationFilter = TypedDict(
    'dataset_versionRelationFilter',
    {
        'is': 'dataset_versionWhereInput',
        'is_not': 'dataset_versionWhereInput',
    },
    total=False,
)


class dataset_versionListRelationFilter(TypedDict, total=False):
    some: 'dataset_versionWhereInput'
    none: 'dataset_versionWhereInput'
    every: 'dataset_versionWhereInput'


class dataset_versionInclude(TypedDict, total=False):
    """dataset_version relational arguments"""
    branch: Union[bool, 'data_branchArgsFromdataset_version']
    dataset: Union[bool, 'datasetArgsFromdataset_version']


class datasetIncludeFromdataset_version(TypedDict, total=False):
    """Relational arguments for dataset_version"""
    dataset_identifier: Union[bool, 'FindManydataset_identifierArgsFromdataset_version']
    dataset_version: Union[bool, 'FindManydataset_versionArgsFromdataset_version']


class datasetArgsFromdataset_version(TypedDict, total=False):
    """Arguments for dataset_version"""
    include: 'datasetIncludeFromdataset'


class FindManydatasetArgsFromdataset_version(TypedDict, total=False):
    """Arguments for dataset_version"""
    take: int
    skip: int
    order_by: Union['datasetOrderByInput', List['datasetOrderByInput']]
    where: 'datasetWhereInput'
    cursor: 'datasetWhereUniqueInput'
    distinct: List['datasetScalarFieldKeys']
    include: 'datasetIncludeFromdataset'


class dataset_identifierIncludeFromdataset_version(TypedDict, total=False):
    """Relational arguments for dataset_version"""
    dataset: Union[bool, 'datasetArgsFromdataset_version']


class dataset_identifierArgsFromdataset_version(TypedDict, total=False):
    """Arguments for dataset_version"""
    include: 'dataset_identifierIncludeFromdataset_identifier'


class FindManydataset_identifierArgsFromdataset_version(TypedDict, total=False):
    """Arguments for dataset_version"""
    take: int
    skip: int
    order_by: Union['dataset_identifierOrderByInput', List['dataset_identifierOrderByInput']]
    where: 'dataset_identifierWhereInput'
    cursor: 'dataset_identifierWhereUniqueInput'
    distinct: List['dataset_identifierScalarFieldKeys']
    include: 'dataset_identifierIncludeFromdataset_identifier'


class dataset_versionIncludeFromdataset_version(TypedDict, total=False):
    """Relational arguments for dataset_version"""
    branch: Union[bool, 'data_branchArgsFromdataset_version']
    dataset: Union[bool, 'datasetArgsFromdataset_version']


class dataset_versionArgsFromdataset_version(TypedDict, total=False):
    """Arguments for dataset_version"""
    include: 'dataset_versionIncludeFromdataset_version'


class FindManydataset_versionArgsFromdataset_version(TypedDict, total=False):
    """Arguments for dataset_version"""
    take: int
    skip: int
    order_by: Union['dataset_versionOrderByInput', List['dataset_versionOrderByInput']]
    where: 'dataset_versionWhereInput'
    cursor: 'dataset_versionWhereUniqueInput'
    distinct: List['dataset_versionScalarFieldKeys']
    include: 'dataset_versionIncludeFromdataset_version'


class data_branchIncludeFromdataset_version(TypedDict, total=False):
    """Relational arguments for dataset_version"""
    dataset_version: Union[bool, 'FindManydataset_versionArgsFromdataset_version']


class data_branchArgsFromdataset_version(TypedDict, total=False):
    """Arguments for dataset_version"""
    include: 'data_branchIncludeFromdata_branch'


class FindManydata_branchArgsFromdataset_version(TypedDict, total=False):
    """Arguments for dataset_version"""
    take: int
    skip: int
    order_by: Union['data_branchOrderByInput', List['data_branchOrderByInput']]
    where: 'data_branchWhereInput'
    cursor: 'data_branchWhereUniqueInput'
    distinct: List['data_branchScalarFieldKeys']
    include: 'data_branchIncludeFromdata_branch'




FindManydataset_versionArgs = FindManydataset_versionArgsFromdataset_version
FindFirstdataset_versionArgs = FindManydataset_versionArgsFromdataset_version


class dataset_versionWhereInput(TypedDict, total=False):
    """dataset_version arguments for searching"""
    id: Union[_int, 'types.IntFilter']
    data_identity_id: Union[_str, 'types.StringFilter']
    data_identity_date: Union[datetime.datetime, 'types.DateTimeFilter']
    branch: 'data_branchRelationFilter'
    dataset: 'datasetRelationFilter'
    datasetId: Union[_int, 'types.IntFilter']
    data_branchId: Union[_int, 'types.IntFilter']

    # should be noted that AND and NOT should be Union['dataset_versionWhereInput', List['dataset_versionWhereInput']]
    # but this causes mypy to hang :/
    AND: List['dataset_versionWhereInput']
    OR: List['dataset_versionWhereInput']
    NOT: List['dataset_versionWhereInput']



# aggregate dataset_version types


class dataset_versionScalarWhereWithAggregatesInput(TypedDict, total=False):
    """dataset_version arguments for searching"""
    id: Union[_int, 'types.IntWithAggregatesFilter']
    data_identity_id: Union[_str, 'types.StringWithAggregatesFilter']
    data_identity_date: Union[datetime.datetime, 'types.DateTimeWithAggregatesFilter']
    datasetId: Union[_int, 'types.IntWithAggregatesFilter']
    data_branchId: Union[_int, 'types.IntWithAggregatesFilter']

    AND: List['dataset_versionScalarWhereWithAggregatesInput']
    OR: List['dataset_versionScalarWhereWithAggregatesInput']
    NOT: List['dataset_versionScalarWhereWithAggregatesInput']



class dataset_versionGroupByOutput(TypedDict, total=False):
    id: _int
    data_identity_id: _str
    data_identity_date: datetime.datetime
    datasetId: _int
    data_branchId: _int
    _sum: 'dataset_versionSumAggregateOutput'
    _avg: 'dataset_versionAvgAggregateOutput'
    _min: 'dataset_versionMinAggregateOutput'
    _max: 'dataset_versionMaxAggregateOutput'
    _count: 'dataset_versionCountAggregateOutput'


class dataset_versionAvgAggregateOutput(TypedDict, total=False):
    """dataset_version output for aggregating averages"""
    id: float
    datasetId: float
    data_branchId: float


class dataset_versionSumAggregateOutput(TypedDict, total=False):
    """dataset_version output for aggregating sums"""
    id: _int
    datasetId: _int
    data_branchId: _int


class dataset_versionScalarAggregateOutput(TypedDict, total=False):
    """dataset_version output including scalar fields"""
    id: _int
    data_identity_id: _str
    data_identity_date: datetime.datetime
    datasetId: _int
    data_branchId: _int


dataset_versionMinAggregateOutput = dataset_versionScalarAggregateOutput
dataset_versionMaxAggregateOutput = dataset_versionScalarAggregateOutput


class dataset_versionMaxAggregateInput(TypedDict, total=False):
    """dataset_version input for aggregating by max"""
    id: bool
    data_identity_id: bool
    data_identity_date: bool
    datasetId: bool
    data_branchId: bool


class dataset_versionMinAggregateInput(TypedDict, total=False):
    """dataset_version input for aggregating by min"""
    id: bool
    data_identity_id: bool
    data_identity_date: bool
    datasetId: bool
    data_branchId: bool


class dataset_versionNumberAggregateInput(TypedDict, total=False):
    """dataset_version input for aggregating numbers"""
    id: bool
    datasetId: bool
    data_branchId: bool


dataset_versionAvgAggregateInput = dataset_versionNumberAggregateInput
dataset_versionSumAggregateInput = dataset_versionNumberAggregateInput


dataset_versionCountAggregateInput = TypedDict(
    'dataset_versionCountAggregateInput',
    {
        'id': bool,
        'data_identity_id': bool,
        'data_identity_date': bool,
        'datasetId': bool,
        'data_branchId': bool,
        '_all': bool,
    },
    total=False,
)

dataset_versionCountAggregateOutput = TypedDict(
    'dataset_versionCountAggregateOutput',
    {
        'id': int,
        'data_identity_id': int,
        'data_identity_date': int,
        'datasetId': int,
        'data_branchId': int,
        '_all': int,
    },
    total=False,
)


dataset_versionKeys = Literal[
    'id',
    'data_identity_id',
    'data_identity_date',
    'branch',
    'dataset',
    'datasetId',
    'data_branchId',
]
dataset_versionScalarFieldKeys = Literal[
    'id',
    'data_identity_id',
    'data_identity_date',
    'datasetId',
    'data_branchId',
]
dataset_versionScalarFieldKeysT = TypeVar('dataset_versionScalarFieldKeysT', bound=dataset_versionScalarFieldKeys)

dataset_versionRelationalFieldKeys = Literal[
        'branch',
        'dataset',
    ]

# data_branch types

class data_branchOptionalCreateInput(TypedDict, total=False):
    """Optional arguments to the data_branch create method"""
    id: _int
    dataset_version: 'dataset_versionCreateManyNestedWithoutRelationsInput'


class data_branchCreateInput(data_branchOptionalCreateInput):
    """Required arguments to the data_branch create method"""
    full_branch_name: _str
    sanitized_branch_name: _str


# TODO: remove this in favour of without explicit relations
# e.g. PostCreateWithoutAuthorInput

class data_branchOptionalCreateWithoutRelationsInput(TypedDict, total=False):
    """Optional arguments to the data_branch create method, without relations"""
    id: _int


class data_branchCreateWithoutRelationsInput(data_branchOptionalCreateWithoutRelationsInput):
    """Required arguments to the data_branch create method, without relations"""
    full_branch_name: _str
    sanitized_branch_name: _str

class data_branchConnectOrCreateWithoutRelationsInput(TypedDict):
    create: 'data_branchCreateWithoutRelationsInput'
    where: 'data_branchWhereUniqueInput'

class data_branchCreateNestedWithoutRelationsInput(TypedDict, total=False):
    create: 'data_branchCreateWithoutRelationsInput'
    connect: 'data_branchWhereUniqueInput'
    connect_or_create: 'data_branchConnectOrCreateWithoutRelationsInput'


class data_branchCreateManyNestedWithoutRelationsInput(TypedDict, total=False):
    create: Union['data_branchCreateWithoutRelationsInput', List['data_branchCreateWithoutRelationsInput']]
    connect: Union['data_branchWhereUniqueInput', List['data_branchWhereUniqueInput']]
    connect_or_create: Union['data_branchConnectOrCreateWithoutRelationsInput', List['data_branchConnectOrCreateWithoutRelationsInput']]

_data_branchWhereUnique_id_Input = TypedDict(
    '_data_branchWhereUnique_id_Input',
    {
        'id': '_int',
    },
    total=True
)

data_branchWhereUniqueInput = _data_branchWhereUnique_id_Input


class data_branchUpdateInput(TypedDict, total=False):
    """Optional arguments for updating a record"""
    id: Union[AtomicIntInput, _int]
    full_branch_name: _str
    sanitized_branch_name: _str
    dataset_version: 'dataset_versionUpdateManyWithoutRelationsInput'


class data_branchUpdateManyMutationInput(TypedDict, total=False):
    """Arguments for updating many records"""
    id: Union[AtomicIntInput, _int]
    full_branch_name: _str
    sanitized_branch_name: _str


class data_branchUpdateManyWithoutRelationsInput(TypedDict, total=False):
    create: List['data_branchCreateWithoutRelationsInput']
    connect: List['data_branchWhereUniqueInput']
    connect_or_create: List['data_branchConnectOrCreateWithoutRelationsInput']
    set: List['data_branchWhereUniqueInput']
    disconnect: List['data_branchWhereUniqueInput']
    delete: List['data_branchWhereUniqueInput']

    # TODO
    # update: List['data_branchUpdateWithWhereUniqueWithoutRelationsInput']
    # updateMany: List['data_branchUpdateManyWithWhereUniqueWithoutRelationsInput']
    # deleteMany: List['data_branchScalarWhereInput']
    # upsert: List['data_branchUpserteWithWhereUniqueWithoutRelationsInput']


class data_branchUpdateOneWithoutRelationsInput(TypedDict, total=False):
    create: 'data_branchCreateWithoutRelationsInput'
    connect: 'data_branchWhereUniqueInput'
    connect_or_create: 'data_branchConnectOrCreateWithoutRelationsInput'
    disconnect: bool
    delete: bool

    # TODO
    # update: 'data_branchUpdateInput'
    # upsert: 'data_branchUpsertWithoutRelationsInput'


class data_branchUpsertInput(TypedDict):
    create: 'data_branchCreateInput'
    update: 'data_branchUpdateInput'  # pyright: ignore[reportIncompatibleMethodOverride]


_data_branch_id_OrderByInput = TypedDict(
    '_data_branch_id_OrderByInput',
    {
        'id': 'SortOrder',
    },
    total=True
)

_data_branch_full_branch_name_OrderByInput = TypedDict(
    '_data_branch_full_branch_name_OrderByInput',
    {
        'full_branch_name': 'SortOrder',
    },
    total=True
)

_data_branch_sanitized_branch_name_OrderByInput = TypedDict(
    '_data_branch_sanitized_branch_name_OrderByInput',
    {
        'sanitized_branch_name': 'SortOrder',
    },
    total=True
)

data_branchOrderByInput = Union[
    '_data_branch_id_OrderByInput',
    '_data_branch_full_branch_name_OrderByInput',
    '_data_branch_sanitized_branch_name_OrderByInput',
]



# recursive data_branch types
# TODO: cleanup these types



data_branchRelationFilter = TypedDict(
    'data_branchRelationFilter',
    {
        'is': 'data_branchWhereInput',
        'is_not': 'data_branchWhereInput',
    },
    total=False,
)


class data_branchListRelationFilter(TypedDict, total=False):
    some: 'data_branchWhereInput'
    none: 'data_branchWhereInput'
    every: 'data_branchWhereInput'


class data_branchInclude(TypedDict, total=False):
    """data_branch relational arguments"""
    dataset_version: Union[bool, 'FindManydataset_versionArgsFromdata_branch']


class datasetIncludeFromdata_branch(TypedDict, total=False):
    """Relational arguments for data_branch"""
    dataset_identifier: Union[bool, 'FindManydataset_identifierArgsFromdata_branch']
    dataset_version: Union[bool, 'FindManydataset_versionArgsFromdata_branch']


class datasetArgsFromdata_branch(TypedDict, total=False):
    """Arguments for data_branch"""
    include: 'datasetIncludeFromdataset'


class FindManydatasetArgsFromdata_branch(TypedDict, total=False):
    """Arguments for data_branch"""
    take: int
    skip: int
    order_by: Union['datasetOrderByInput', List['datasetOrderByInput']]
    where: 'datasetWhereInput'
    cursor: 'datasetWhereUniqueInput'
    distinct: List['datasetScalarFieldKeys']
    include: 'datasetIncludeFromdataset'


class dataset_identifierIncludeFromdata_branch(TypedDict, total=False):
    """Relational arguments for data_branch"""
    dataset: Union[bool, 'datasetArgsFromdata_branch']


class dataset_identifierArgsFromdata_branch(TypedDict, total=False):
    """Arguments for data_branch"""
    include: 'dataset_identifierIncludeFromdataset_identifier'


class FindManydataset_identifierArgsFromdata_branch(TypedDict, total=False):
    """Arguments for data_branch"""
    take: int
    skip: int
    order_by: Union['dataset_identifierOrderByInput', List['dataset_identifierOrderByInput']]
    where: 'dataset_identifierWhereInput'
    cursor: 'dataset_identifierWhereUniqueInput'
    distinct: List['dataset_identifierScalarFieldKeys']
    include: 'dataset_identifierIncludeFromdataset_identifier'


class dataset_versionIncludeFromdata_branch(TypedDict, total=False):
    """Relational arguments for data_branch"""
    branch: Union[bool, 'data_branchArgsFromdata_branch']
    dataset: Union[bool, 'datasetArgsFromdata_branch']


class dataset_versionArgsFromdata_branch(TypedDict, total=False):
    """Arguments for data_branch"""
    include: 'dataset_versionIncludeFromdataset_version'


class FindManydataset_versionArgsFromdata_branch(TypedDict, total=False):
    """Arguments for data_branch"""
    take: int
    skip: int
    order_by: Union['dataset_versionOrderByInput', List['dataset_versionOrderByInput']]
    where: 'dataset_versionWhereInput'
    cursor: 'dataset_versionWhereUniqueInput'
    distinct: List['dataset_versionScalarFieldKeys']
    include: 'dataset_versionIncludeFromdataset_version'


class data_branchIncludeFromdata_branch(TypedDict, total=False):
    """Relational arguments for data_branch"""
    dataset_version: Union[bool, 'FindManydataset_versionArgsFromdata_branch']


class data_branchArgsFromdata_branch(TypedDict, total=False):
    """Arguments for data_branch"""
    include: 'data_branchIncludeFromdata_branch'


class FindManydata_branchArgsFromdata_branch(TypedDict, total=False):
    """Arguments for data_branch"""
    take: int
    skip: int
    order_by: Union['data_branchOrderByInput', List['data_branchOrderByInput']]
    where: 'data_branchWhereInput'
    cursor: 'data_branchWhereUniqueInput'
    distinct: List['data_branchScalarFieldKeys']
    include: 'data_branchIncludeFromdata_branch'




FindManydata_branchArgs = FindManydata_branchArgsFromdata_branch
FindFirstdata_branchArgs = FindManydata_branchArgsFromdata_branch


class data_branchWhereInput(TypedDict, total=False):
    """data_branch arguments for searching"""
    id: Union[_int, 'types.IntFilter']
    full_branch_name: Union[_str, 'types.StringFilter']
    sanitized_branch_name: Union[_str, 'types.StringFilter']
    dataset_version: 'dataset_versionListRelationFilter'

    # should be noted that AND and NOT should be Union['data_branchWhereInput', List['data_branchWhereInput']]
    # but this causes mypy to hang :/
    AND: List['data_branchWhereInput']
    OR: List['data_branchWhereInput']
    NOT: List['data_branchWhereInput']



# aggregate data_branch types


class data_branchScalarWhereWithAggregatesInput(TypedDict, total=False):
    """data_branch arguments for searching"""
    id: Union[_int, 'types.IntWithAggregatesFilter']
    full_branch_name: Union[_str, 'types.StringWithAggregatesFilter']
    sanitized_branch_name: Union[_str, 'types.StringWithAggregatesFilter']

    AND: List['data_branchScalarWhereWithAggregatesInput']
    OR: List['data_branchScalarWhereWithAggregatesInput']
    NOT: List['data_branchScalarWhereWithAggregatesInput']



class data_branchGroupByOutput(TypedDict, total=False):
    id: _int
    full_branch_name: _str
    sanitized_branch_name: _str
    _sum: 'data_branchSumAggregateOutput'
    _avg: 'data_branchAvgAggregateOutput'
    _min: 'data_branchMinAggregateOutput'
    _max: 'data_branchMaxAggregateOutput'
    _count: 'data_branchCountAggregateOutput'


class data_branchAvgAggregateOutput(TypedDict, total=False):
    """data_branch output for aggregating averages"""
    id: float


class data_branchSumAggregateOutput(TypedDict, total=False):
    """data_branch output for aggregating sums"""
    id: _int


class data_branchScalarAggregateOutput(TypedDict, total=False):
    """data_branch output including scalar fields"""
    id: _int
    full_branch_name: _str
    sanitized_branch_name: _str


data_branchMinAggregateOutput = data_branchScalarAggregateOutput
data_branchMaxAggregateOutput = data_branchScalarAggregateOutput


class data_branchMaxAggregateInput(TypedDict, total=False):
    """data_branch input for aggregating by max"""
    id: bool
    full_branch_name: bool
    sanitized_branch_name: bool


class data_branchMinAggregateInput(TypedDict, total=False):
    """data_branch input for aggregating by min"""
    id: bool
    full_branch_name: bool
    sanitized_branch_name: bool


class data_branchNumberAggregateInput(TypedDict, total=False):
    """data_branch input for aggregating numbers"""
    id: bool


data_branchAvgAggregateInput = data_branchNumberAggregateInput
data_branchSumAggregateInput = data_branchNumberAggregateInput


data_branchCountAggregateInput = TypedDict(
    'data_branchCountAggregateInput',
    {
        'id': bool,
        'full_branch_name': bool,
        'sanitized_branch_name': bool,
        '_all': bool,
    },
    total=False,
)

data_branchCountAggregateOutput = TypedDict(
    'data_branchCountAggregateOutput',
    {
        'id': int,
        'full_branch_name': int,
        'sanitized_branch_name': int,
        '_all': int,
    },
    total=False,
)


data_branchKeys = Literal[
    'id',
    'full_branch_name',
    'sanitized_branch_name',
    'dataset_version',
]
data_branchScalarFieldKeys = Literal[
    'id',
    'full_branch_name',
    'sanitized_branch_name',
]
data_branchScalarFieldKeysT = TypeVar('data_branchScalarFieldKeysT', bound=data_branchScalarFieldKeys)

data_branchRelationalFieldKeys = Literal[
        'dataset_version',
    ]



# we have to import ourselves as types can be namespaced to types
from . import types, enums, models, fields